{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "installazioni delle librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from PIL import Image\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import scipy.spatial\n",
    "import scipy.linalg\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import check_grad\n",
    "from functools import partial\n",
    "from scipy.optimize import approx_fprime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "codice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'predictions_saved.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m datas \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredictions_saved.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_point_clouds\u001b[39m(pred_dict):\n\u001b[0;32m      5\u001b[0m     X_pred, Y_pred \u001b[38;5;241m=\u001b[39m [], []  \u001b[38;5;66;03m# Vettori delle coordinate predette\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'predictions_saved.npy'"
     ]
    }
   ],
   "source": [
    "datas = np.load(\"predictions_saved.npy\", allow_pickle=True).item()\n",
    "\n",
    "def extract_point_clouds(pred_dict):\n",
    "\n",
    "    X_pred, Y_pred = [], []  # Vettori delle coordinate predette\n",
    "    X_real, Y_real = [], []  # Vettori delle coordinate reali\n",
    "    img_names = []  # Lista dei nomi delle immagini\n",
    "\n",
    "    # Iteriamo su tutte le immagini nel dizionario\n",
    "    for img_name, joints in pred_dict.items():\n",
    "        joints = np.array(joints)  # Convertiamo in numpy array\n",
    "    \n",
    "        x_pred_joints = joints[:, 0, 0]  # Tutte le X predette\n",
    "        y_pred_joints = joints[:, 0, 1]  # Tutte le Y predette\n",
    "        x_real_joints = joints[:, 1, 0]  # Tutte le X reali\n",
    "        y_real_joints = joints[:, 1, 1]  # Tutte le Y reali\n",
    "\n",
    "        # Aggiungiamo i dati alle liste\n",
    "        X_pred.append(x_pred_joints)\n",
    "        Y_pred.append(y_pred_joints)\n",
    "        X_real.append(x_real_joints)\n",
    "        Y_real.append(y_real_joints)\n",
    "        img_names.append(img_name)  # Salviamo anche il nome dell'immagine\n",
    "\n",
    "    # Convertiamo tutto in NumPy array per efficienza\n",
    "    return np.array(X_pred), np.array(Y_pred), np.array(X_real), np.array(Y_real), img_names\n",
    "\n",
    "X_pred,Y_pred,X_real,Y_real,img_names=extract_point_clouds(datas)\n",
    "\n",
    "X_pred = X_pred.reshape(-1, 1)  \n",
    "Y_pred = Y_pred.reshape(-1, 1)\n",
    "\n",
    "X= np.hstack((X_pred, Y_pred))  #nuvola di partenza \n",
    "\n",
    "X_real = X_real.reshape(-1, 1)  # Shape (N, 1)\n",
    "Y_real=  Y_real.reshape(-1, 1)  # Shape (N, 1)\n",
    "\n",
    "Y = np.hstack((X_real, Y_real))\n",
    "\n",
    "def remove_2d_outliers(points1,points2, soglia):\n",
    "   \n",
    "    zscores = np.abs(zscore(points1, axis=0))\n",
    "    mask = (zscores < soglia).all(axis=1)\n",
    "    return points1[mask],points2[mask]\n",
    "\n",
    "Y,X=remove_2d_outliers(Y,X,3)\n",
    "\n",
    "\n",
    "def rototraslazione(angolo,X):\n",
    "    \n",
    "    sigma=5\n",
    "\n",
    "    angolo=np.radians(angolo)\n",
    "\n",
    "    matrice_rotazione = np.array([[np.cos(angolo), -np.sin(angolo)],[np.sin(angolo),  np.cos(angolo)]])\n",
    "\n",
    "    traslazione = np.array([5, 20])\n",
    "\n",
    "    P_trasformata = np.dot(X, matrice_rotazione) + traslazione \n",
    "\n",
    "    rumore=np.random.normal(4,sigma,X.shape)\n",
    "\n",
    "    P_trasformata+=rumore\n",
    "\n",
    "    return P_trasformata\n",
    "\n",
    "#Y=rototraslazione(65,X)\n",
    "\n",
    "K=50\n",
    "\n",
    "def RBF_esponenziale(C1,C2,X,sigma):\n",
    "    X1, X2 = X[:, 0][:, np.newaxis], X[:, 1][:, np.newaxis]\n",
    "    matrix = (X1 - C1)**2  + (X2 - C2)**2\n",
    "    return  np.exp(-matrix/2*sigma)\n",
    "\n",
    "def RBF_logaritmica(C1,C2,X,sigma):\n",
    "    X1, X2 = X[:, 0][:, np.newaxis], X[:, 1][:, np.newaxis]\n",
    "    matrix = (X1 - C1)**2  + (X2 - C2)**2\n",
    "    return  np.log(1+sigma*matrix)\n",
    "\n",
    "def RBF_multiquadratica(C1,C2,X,sigma):\n",
    "    X1, X2 = X[:, 0][:, np.newaxis], X[:, 1][:, np.newaxis]\n",
    "    matrix = (X1 - C1)**2  + (X2 - C2)**2\n",
    "    return  np.sqrt(matrix+sigma**2)\n",
    "\n",
    "def matrix_A(C,X,sigma,epsilon,func):\n",
    "    C1=C[:,0]\n",
    "    C2=C[:,1]\n",
    "    starting_matrix=func(C1,C2,X,sigma)\n",
    "    N, K = starting_matrix.shape\n",
    "    zero_block = np.zeros((N, K), dtype= starting_matrix.dtype)\n",
    "    top = np.hstack((starting_matrix, zero_block)) \n",
    "    bottom = np.hstack((zero_block, starting_matrix)) \n",
    "    matrix= np.vstack((top, bottom)) \n",
    "    I = np.identity(2*K)*(np.sqrt(epsilon))\n",
    "    A = np.vstack((matrix, I))\n",
    "    return A \n",
    "\n",
    "def vector_b(Y,K):\n",
    "    vettore=Y.flatten(order='F')\n",
    "    zeri=np.zeros(2*K)\n",
    "    b = np.concatenate((vettore, zeri))\n",
    "    return b \n",
    "\n",
    "def gradiente_coniugato(W,C,X,Y,sigma,epsilon,tol,func,K):\n",
    "    k=0\n",
    "    A=matrix_A(C,X,sigma,epsilon,func)\n",
    "    r=vector_b(Y,K)-np.dot(A,W) #(2N+2K)\n",
    "    d=np.dot(A.T,r) #2K\n",
    "    #print('la prima direzione è',d)\n",
    "    gamma=np.linalg.norm(np.dot(A.T,r))**2 \n",
    "    #print('la norma del gradiente è', gamma)\n",
    "    #print('questo è W prima di essere ottimizzato',W)\n",
    "    while gamma>=tol:\n",
    "        q=np.dot(A,d) #2n+2k\n",
    "        alfa=gamma/(np.linalg.norm(q)**2) #scalare\n",
    "        W=W+alfa*d #2k\n",
    "        #print('ho aggiornato W',W)\n",
    "        r=r-alfa*q #2N+2K\n",
    "        g=-np.dot(A.T,r)\n",
    "        gamma_nuovo=np.linalg.norm(g)**2\n",
    "        #print('la nuova norma del gradiente è',gamma_nuovo)\n",
    "        beta=gamma_nuovo/gamma\n",
    "        gamma=gamma_nuovo\n",
    "        d=-g+beta*d\n",
    "        #print('la nuova direzione è',d)\n",
    "        k+=1\n",
    "    print('norma gradiente',gamma)\n",
    "    diff=np.dot(A,W)-vector_b(Y,K)\n",
    "    norma=0.5*((np.linalg.norm(diff))**2)\n",
    "    return W,norma\n",
    "\n",
    "def plot_selected_points(clouds, K=16):\n",
    "   \n",
    "    colors = ['red', 'blue', 'green']\n",
    "    markers = ['o', 's', '^']\n",
    "    labels = ['Nuvola 1', 'Nuvola 2', 'Nuvola 3']\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    for i, cloud in enumerate(clouds):\n",
    "        plt.scatter(cloud[:K, 0], cloud[:K, 1], color=colors[i], marker=markers[i], label=labels[i], alpha=0.7)\n",
    "\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.legend()\n",
    "    plt.title(f'Visualizzazione dei primi {K} punti di 3 nuvole di punti')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def nuvola_predetta(W,X,C,K,sigma,func):\n",
    "    C1=C[:,0]\n",
    "    C2=C[:,1]\n",
    "    matrice=func(C1,C2,X,sigma)\n",
    "    W_matrix=np.column_stack((W[:K], W[K:]))\n",
    "    cloud3=np.dot(matrice,W_matrix)\n",
    "    return cloud3\n",
    "\n",
    "def compute_k_centers(points, k):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=32)\n",
    "    kmeans.fit(points)\n",
    "    return kmeans.cluster_centers_, kmeans.labels_\n",
    "\n",
    "centers, labels = compute_k_centers(X,K)\n",
    "sigmus=[10,20,30,40,50,60,80,100,200,300,400,500,600]\n",
    "rbf_functions =[RBF_multiquadratica]\n",
    "diz={}\n",
    "for RBF in rbf_functions:\n",
    "    nome_RBF = RBF.__name__  # Ottiene il nome della funzione come stringa\n",
    "    for sigma in sigmus:\n",
    "        #print(f'Sto processando RBF={nome_RBF}, sigma={sigma}')\n",
    "        lista = []\n",
    "        np.random.seed(32)\n",
    "        W = np.random.random(2*K)\n",
    "        C = centers\n",
    "        epsilon = 0.5\n",
    "        tol = 10**-6\n",
    "        # Calcolo con gradiente coniugato\n",
    "        W, norma= gradiente_coniugato(W, C, X, Y, sigma, epsilon, tol, RBF,K)\n",
    "        # Salviamo il valore della norma\n",
    "        lista.append(norma)\n",
    "        # Salviamo i risultati nel dizionario\n",
    "        diz[(RBF, sigma)] = lista\n",
    "# Troviamo il valore minimo\n",
    "min_key, min_value = min(diz.items(), key=lambda x: min(x[1]))\n",
    "\n",
    "# Stampiamo il miglior risultato\n",
    "print(f\"Il miglior risultato è stato ottenuto con:\")\n",
    "print(f\"- RBF: {min_key[0]}\")\n",
    "print(f\"- Sigma: {min_key[1]}\")\n",
    "print(f\"- Valore minimo della norma: {min_value}\")\n",
    "best_rbf = min_key[0]\n",
    "best_sigma = min_key[1]\n",
    "W=np.random.random(2*K)\n",
    "C=centers\n",
    "epsilon=0.5\n",
    "tol=10**-10\n",
    "W_opt,norma=gradiente_coniugato(W,C,X,Y,best_sigma,epsilon,tol,best_rbf,K)\n",
    "print('norma',norma)\n",
    "cloud3=nuvola_predetta(W_opt,X,C,K,best_sigma,best_rbf)\n",
    "clouds=[X,Y,cloud3]\n",
    "plot_selected_points(clouds,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
